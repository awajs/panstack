Metadata-Version: 2.4
Name: panstack
Version: 0.0.1
Summary: Compute controllable action-pan composites from burst RAWs.
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: rawpy
Requires-Dist: opencv-python
Requires-Dist: numpy
Requires-Dist: tifffile

# panstack

`panstack` is a computational photography tool for generating **Pixel-style “action pan”** images from burst RAWs (Sony A6700 tested, but works with similar cameras).

It creates images where:
- **selected faces (and optionally upper/full body regions) remain sharp** (taken from a chosen “base” frame)
- the rest of the scene becomes a **time-accumulated motion field** via stacking and motion-shaped kernels
- outputs are **color-managed** (linear processing → sRGB encoding) and **Photoshop-friendly** (TIFF with embedded sRGB ICC)

---

## Key ideas

### 1) Base frame
A “base” frame is selected automatically as the frame with the **sharpest detected face** (using an 8‑bit detection proxy). The base is the source of the **sharp/frozen region**.

### 2) Stacking
A set of frames around the base are combined with a temporal weighting to form a stacked image. Stacking can be aligned (stabilized) or unaligned.

### 3) Motion-shaped blur kernels (optional)
Instead of a generic blur, `panstack` can build a blur kernel from the **actual burst motion path** (“trajectory” kernel). You can apply this blur per-region:
- background (strong)
- body region (medium)
- frozen region (none)

### 4) Background stabilization (optional)
`panstack` can keep the background **sharp/stabilized** by using aligned stacking and skipping kernel blur on the background (and optionally using median stacking to remove ghosting).

### 5) Output & metadata
- Output can be a **file** or a **directory** (auto-naming).
- A **sidecar JSON** is always written with all settings.
- TIFF outputs embed the same JSON in TIFF **ImageDescription** and include an **sRGB ICC profile**.

---

## Installation

### Requirements
- Python 3.10+ (3.11 stable recommended)
- Windows/macOS/Linux
- CPU-only (GPU not required)

### Install
```bash
python -m venv .venv
# Windows Git Bash:
source .venv/Scripts/activate
# macOS/Linux:
# source .venv/bin/activate

pip install -U pip
pip install -e .
pip install pillow tifffile
```

### Face detector model files (OpenCV DNN)
Place these in:
`src/panstack/models/`

- `deploy.prototxt`
- `res10_300x300_ssd_iter_140000.caffemodel`

---

## Directory layout

Recommended working layout:
```
data/
  bursts/
    session1/      # input ARW burst files
  outputs/         # generated TIFF/PNG + JSON sidecars
```

---

## Quick start

### 1) Preview detected faces (numbered IDs)
```bash
panstack --in data/bursts/session1 --out data/outputs --preview-faces
```

Creates:
- `data/outputs/preview_faces.png`

Faces are numbered **1..N** (1 is the most prominent face: largest area, then confidence).

### 2) Generate a typical Pixel-like action-pan
```bash
panstack --in data/bursts/session1 --out data/outputs \
  --freeze-faces 1 --freeze-region face \
  --align-bg on \
  --k 14 --mode trailing \
  --blur-model trajectory \
  --bg-mode blur --bg-blur 1.0 --body-blur 0.35 \
  --bps 16
```

### 3) Sharp stabilized city background (no blur on background)
```bash
panstack --in data/bursts/session1 --out data/outputs \
  --bg-mode stabilize --bg-stack median \
  --align-bg on \
  --freeze-faces all --freeze-region face \
  --k 14 --mode trailing \
  --blur-model trajectory \
  --body-blur 0.35 \
  --bps 16
```

---

# CLI Reference (all parameters)

> Tip: `--out` can be either a filename (explicit) or a directory (auto-named output).

---

## Input / Output

### `--in <path>` (required)
Input directory containing burst RAW files (Sony `.ARW`).

### `--out <path>` (required)
Output **file** or **directory**.

- If a file extension is present (`.tif`, `.tiff`, `.png`, `.jpg`), that exact filename is used.
- Otherwise, `--out` is treated as a **directory**, and a unique name is generated.

---

## Face selection & sharp region

### `--preview-faces`
Writes a preview image showing detected face boxes with numeric IDs and exits.

### `--freeze-faces <ids|all>`
Which face IDs (from the base frame preview) should remain sharp.

- `1` → keep face #1 sharp
- `1,2` → keep faces #1 and #2 sharp
- `all` → keep all detected faces sharp

Default: `1`

### `--freeze-region <face|upper|full>`
Expands the sharp region around each selected face.

- `face` (default): only face box
- `upper`: head + torso heuristic region (good for waist-up shots)
- `full`: larger region (useful when subject is fully visible)

---

## Background alignment & stabilization

### `--align-bg <on|off>`
Controls whether frames are geometrically aligned (warped) to the base frame.

- `on` (default): Pixel-like stabilization; smoother smears; needed for sharp background stabilization.
- `off`: raw stacking; more chaotic motion; can look more “in-camera”.

### `--bg-mode <blur|stabilize>`
Controls whether the background ends up motion-blurred or stabilized.

- `blur` (default): background can be blurred via kernels (`--bg-blur`).
- `stabilize`: background is kept sharp (aligned stack) and kernel blur is **skipped** on background.
  - If you set `--bg-mode stabilize` while `--align-bg off`, the pipeline forces alignment on (and records it in metadata).

### `--bg-stack <mean|median>`
Only meaningful when `--bg-mode stabilize`.

- `mean` (default): uses the aligned weighted stack result.
- `median`: uses a median of aligned frames (when enough aligned frames are available) to reduce ghosting from moving people/cars.

---

## Temporal stacking controls

### `--k <int>`
Controls the **temporal window** size around the base frame.

Typical values:
- 6–10 subtle
- 12–18 strong
- 20+ very expressive / abstract

### `--mode <symmetric|trailing|leading>`
Which frames around the base frame are included.

### `--weight-sigma <float>`
Controls how strongly the stack weights concentrate around the base.

Typical:
- 0.5 crisp
- 0.7 default
- 1.0 stronger motion

### `--scale <float>`
Downscale factor for RAW decode (for speed). `1.0` is full resolution.

---

## Motion-shaped blur controls

### `--blur-model <none|line|trajectory>`
Selects how the motion blur kernel is created.

- `none`: stacking only, no kernel blur
- `line`: single direction line kernel derived from mean motion
- `trajectory` (default): kernel is rasterized from the burst motion path

### `--bg-blur <float>`
Background blur amount (0..1 typical), only meaningful when `--bg-mode blur`.

### `--body-blur <float>`
Body-region blur strength (0..1 typical).

### `--kernel-softness <float>`
Gaussian smoothing applied to the kernel (in pixels).

### `--min-kernel <int>`
Minimum kernel size (odd).

---

## Face detection controls (proxy only)

### `--face-conf <float>`
Face detection confidence threshold.

### `--detect-gain <float>`
Gain multiplier for the detection proxy.

### `--detect-gamma <float>`
Gamma applied to detection proxy (values <1 brighten shadows).

### `--detect-clahe`
Apply CLAHE to detection proxy.

---

## Output bit depth & exposure

### `--bps <8|16>`
Output bit depth. 16 recommended for grading.

### `--auto-expose <on|off>`
Automatic exposure normalization in **linear space** before sRGB encoding.

### `--exposure-gain <float>`
Manual exposure multiplier applied after auto exposure (if enabled).

### `--expose-percentile <float>`
Percentile used for auto exposure.

### `--expose-target <float>`
Target luminance for the chosen percentile.

### `--min-gain`, `--max-gain`
Clamp the auto-exposure gain.

---

## Metadata & reproducibility

For each output:
- A sidecar JSON is written: `output.ext.json`
- TIFFs embed the JSON in TIFF **ImageDescription**
- TIFFs include an **sRGB ICC profile** (Photoshop-friendly)

---

## Practical presets

### Pixel-like (balanced)
```bash
--k 14 --mode trailing --weight-sigma 0.7 --align-bg on --blur-model trajectory \
--bg-mode blur --bg-blur 1.0 --body-blur 0.35 --kernel-softness 0.8
```

### Strong motion
```bash
--k 18 --mode trailing --weight-sigma 1.0 --align-bg on --blur-model trajectory \
--bg-mode blur --bg-blur 1.0 --body-blur 0.25 --kernel-softness 1.2
```

### Sharp stabilized city background
```bash
--bg-mode stabilize --bg-stack median --align-bg on \
--blur-model trajectory --body-blur 0.35
```

---

## Notes / limitations

- Stabilization of faces/bodies is base-frame freezing (not tracking across frames).
- Per-region kernels use burst motion inferred from affine transforms (not full optical flow).
- Median stabilization depends on having enough aligned frames.

---

## License

Choose your preferred license (MIT is a good default).
